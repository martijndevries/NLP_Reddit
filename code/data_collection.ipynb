{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15bf9c6-3ae8-41dc-80d0-f9cc4aabfede",
   "metadata": {},
   "source": [
    "# Data Collection \n",
    "\n",
    "This notebook 1 (out of 5) for <b>Project 3</b> of the GA Data Science Immersive<br>\n",
    "Notebook by: <b>Martijn de Vries</b><br>\n",
    "martijndevries91@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aad84c-d2c4-4f6f-a091-4cffe7126ffc",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "A US political consultancy company is researching how news sources and discussed topics differ between the US political mainstream and the conservative right-wing media. In the last decade or so, the US political right-wing has been increasingly described as living in an entirely separate information ecosystem from the political mainstream. In order to gauge how intense this effect is, we will collect, process, and classify the Reddit content of two politically-themed subreddit that reflect the mainstream and conservative voters respectively: <b>r/politics</b> and <b>r/conservative</b>. \n",
    "\n",
    "For this project, we will build two separate branches of models: one for post submissions (largely consisting of links to news sites), and another for comments (consisting of actual Reddit users discussing political news). As this is a binary classification problem where the two classes are of equal interest and will be approximately balanced, we will use the accuracy score as the main metric to gauge the success of the classification model. \n",
    "\n",
    "Because political news is always evolving, we have chosen a specific moment in time: the month leading up to the 2022 midterms, October 6th to November 6th 2022. This ensures that 1) the same news cycle is covered for both subreddits, 2) both subreddits were at peak activity, and 3) maximum potential for interesting insights in the way that news is discussed within these two subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad31c95-8e0a-4d6e-9ebd-03b199a60419",
   "metadata": {},
   "source": [
    "## In this Notebook\n",
    "\n",
    "I will use the Pushshift API to obtain data from the two subreddits (r/politics and r/conservative) for the specified data. I will then extract the information I want from the obtained data, convert to a pandas dataframe and save the dataframes to two csv files: all_submissions.csv and all_comments.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7585b2c-24c1-49fb-af7f-c9e77e7ba8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime as dt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf6fc1-9b7a-4c32-85df-75a91f4bcb40",
   "metadata": {},
   "source": [
    "## Posts\n",
    "\n",
    "The first thing I would like to is to collect all posts made in the specified month (October 6th, 2022 until November 6th, 2022). First let's define the two subreddits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4be7da40-b915-460d-8d3a-f8677e0e6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit1 = 'politics'\n",
    "subreddit2 = 'conservative'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a03375-7540-4c6d-948f-692e5465822c",
   "metadata": {},
   "source": [
    "Now I'll write a function to actually collect data with Pushshift API. From previous experiments, it seems that I'm not always able to succesfully connect to the API. So I'll build in a couple of failsafes - I'll loop over each day of the month, and collect all the data. At the end of the loop, repeat for the days where it didn't manage to connect succesfully, until all data has been collected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "11f2f172-b419-4554-af56-62e545d6259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_subreddit_data(subreddit, start_date='10-06-2022', n_days=30, rtype='submission'):\n",
    "    \"\"\"\n",
    "    This function collects data (submissions, or comments) from a given subreddit, from a given range of days, using the pushshift API\n",
    "    Because the pushshift API is kinda finnicky and API requests aren't always succesful, I'm wrapping everything in a while loop\n",
    "    so that it can keep trying until it's made a succesful request for each of my specified dates\n",
    "    Returns: a list of json objects for each of the days\n",
    "    \"\"\"\n",
    "    \n",
    "    pushshift_url= 'https://api.pushshift.io/reddit/' + rtype + '/search'\n",
    "    print(pushshift_url)\n",
    "    subr_data = []\n",
    "    success_list = []\n",
    "    mm, dd, yy = start_date.split('-')\n",
    "    tot_posts = 0\n",
    "    #only stop when data was succesfully retrieved from all the days\n",
    "    q = 0 \n",
    "    while len(success_list) < n_days:\n",
    "        s_epoch_start = int(dt.datetime(int(yy),int(mm),int(dd),0,0).timestamp())\n",
    "\n",
    "        for i in range(1, n_days+1):\n",
    "            print('-' * 30)\n",
    "\n",
    "            s_epoch_start += 24*3600\n",
    "            if i in success_list: continue\n",
    "            print(f'Day of the month {i}')\n",
    "            s_epoch_end = s_epoch_start + 24*3600\n",
    "            \n",
    "            params = {'subreddit':subreddit, 'since':s_epoch_start, 'until':s_epoch_end , 'size':1000}\n",
    "            res = requests.get(pushshift_url, params)\n",
    "            print(f'Status code: {res.status_code}')\n",
    "            \n",
    "            if res.status_code != 200:\n",
    "                print('Connection unsuccessful')\n",
    "                continue\n",
    "            else:\n",
    "                data = res.json()\n",
    "                if len(data['data']) == 0:\n",
    "                    print('Connection succesful but no data retrieved.') \n",
    "                    continue\n",
    "                subr_data.append(data)\n",
    "                success_list.append(i) #don't need try this day again on subsequent loops\n",
    "                tot_posts += len(data['data'])\n",
    "                \n",
    "            time.sleep(15) #polite\n",
    "        print(f'Total length of the list: {len(success_list)}')\n",
    "        q +=1\n",
    "        if q == 10: break # Failsafe to make sure that if the API is down, the while loop doesn't keep going forever\n",
    "    print(f'Great Success! Total number of posts/comments retrieved: {tot_posts}')\n",
    "    return subr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "718ca04a-9048-4e25-a4ce-b6772023ea89",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 2\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 3\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 4\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 7\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 8\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 9\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 10\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 11\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 12\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 13\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 15\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 16\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 17\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 19\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 20\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 21\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 22\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 23\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 24\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 25\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 27\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 28\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 29\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 30\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 31\n",
      "Status code: 200\n",
      "Total length of the list: 31\n",
      "Great Success! Total number of posts retrieved: 10010\n"
     ]
    }
   ],
   "source": [
    "subr1_data = collect_subreddit_data(subreddit1, start_date='10-06-2022', n_days=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ddcdfe7-63c0-46c9-a823-3a77fc6db438",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 524\n",
      "Connection unsuccessful\n",
      "------------------------------\n",
      "Day of the month 2\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 3\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 4\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 524\n",
      "Connection unsuccessful\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 7\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 8\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 9\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 10\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 11\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 12\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 13\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 524\n",
      "Connection unsuccessful\n",
      "------------------------------\n",
      "Day of the month 15\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 16\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 17\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 19\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 20\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 21\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 22\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 23\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 24\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 25\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 27\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 28\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 29\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 30\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 31\n",
      "Status code: 200\n",
      "Total length of the list: 28\n",
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 200\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 200\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 200\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Total length of the list: 31\n",
      "Great Success! Total number of posts retrieved: 10411\n"
     ]
    }
   ],
   "source": [
    "subr2_data = collect_subreddit_data(subreddit2, start_date='10-06-2022', n_days=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2b8872a5-2c71-4975-9ba7-52fa1ef1b775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_awardings', 'allow_live_comments', 'archived', 'author', 'author_created_utc', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders', 'can_gild', 'category', 'content_categories', 'contest_mode', 'created_utc', 'discussion_type', 'distinguished', 'domain', 'edited', 'gilded', 'gildings', 'hidden', 'hide_score', 'id', 'is_created_from_ads_ui', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked', 'media', 'media_embed', 'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'post_hint', 'preview', 'pwls', 'quarantine', 'removed_by', 'removed_by_category', 'retrieved_on', 'score', 'secure_media', 'secure_media_embed', 'selftext', 'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_name_prefixed', 'subreddit_subscribers', 'subreddit_type', 'suggested_sort', 'thumbnail', 'thumbnail_height', 'thumbnail_width', 'title', 'top_awarded_type', 'total_awards_received', 'treatment_tags', 'upvote_ratio', 'url', 'url_overridden_by_dest', 'view_count', 'whitelist_status', 'wls', 'retrieved_utc', 'updated_utc', 'utc_datetime_str'])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the keys of a single post dictionary\n",
    "subr1_data[0]['data'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3dbbc8-0847-4f88-a800-015ad9058a67",
   "metadata": {},
   "source": [
    "subr1_data and subr2_data are now lists with the following structure:\n",
    "1) each entry is all the posts for a given day\n",
    "2) indexing into the lists, selecting ['data'], gives me a list with all the data for that day\n",
    "3) indexing into this gives me a dictionary with the data for a single post\n",
    "\n",
    "Let's write a function to take these lists, and return a pandas dataframe with\n",
    "1) the unique ID of the post\n",
    "2) the time it was posted\n",
    "3) the title\n",
    "4) the selftext (if present)\n",
    "5) the URL the post links to\n",
    "5) the number of comments\n",
    "6) the upvote ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "70967b21-e38c-484a-99ad-b3d138b4e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submissions_df(subr_data, subr_name):\n",
    "    \n",
    "    #create a new list of dictionaries that has the format we want\n",
    "    df_l = []\n",
    "    features = ['id', 'created_utc', 'title', 'selftext', 'url', 'num_comments', 'upvote_ratio']\n",
    "    for subs_day in subr_data:\n",
    "        \n",
    "        for post in subs_day['data']:\n",
    "            post_dict = {features[i]:post[x] for i,x in enumerate(features)}\n",
    "            df_l.append(post_dict)\n",
    "            \n",
    "    sub_df = pd.DataFrame(df_l)\n",
    "    sub_df['subreddit'] = subr_name\n",
    "    sub_df.set_index('id', inplace=True)\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7dc7c-d482-4754-8339-4e991739164f",
   "metadata": {},
   "source": [
    "Let's try this out for our first subreddit, r/politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "28e65dc9-daaa-4caf-8173-d266a5979906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010, 7)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_df = create_submissions_df(subr1_data, subreddit1)\n",
    "subr1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4a098150-feb4-4357-b629-3dceb5ffe47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xylvpq</th>\n",
       "      <td>1665212044</td>\n",
       "      <td>Editorial: Hey, QAnon — Texas had an actual ch...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.houstonchronicle.com/opinion/edito...</td>\n",
       "      <td>688</td>\n",
       "      <td>0.97</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xylh3y</th>\n",
       "      <td>1665210574</td>\n",
       "      <td>Sanders: Biden’s Marijuana Pardons Are Good — ...</td>\n",
       "      <td></td>\n",
       "      <td>https://truthout.org/articles/sanders-bidens-m...</td>\n",
       "      <td>269</td>\n",
       "      <td>0.97</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xyla6d</th>\n",
       "      <td>1665209886</td>\n",
       "      <td>Elon Musk suggests making Taiwan a ‘special ad...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>0.26</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xykwzh</th>\n",
       "      <td>1665208590</td>\n",
       "      <td>Anyone else in Chicago noticing how Fox News k...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xykox1</th>\n",
       "      <td>1665207791</td>\n",
       "      <td>Urfi wore a bold saree! Spread the flames of h...</td>\n",
       "      <td></td>\n",
       "      <td>https://countryconnect.in/entertainment-news/u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        created_utc                                              title  \\\n",
       "id                                                                       \n",
       "xylvpq   1665212044  Editorial: Hey, QAnon — Texas had an actual ch...   \n",
       "xylh3y   1665210574  Sanders: Biden’s Marijuana Pardons Are Good — ...   \n",
       "xyla6d   1665209886  Elon Musk suggests making Taiwan a ‘special ad...   \n",
       "xykwzh   1665208590  Anyone else in Chicago noticing how Fox News k...   \n",
       "xykox1   1665207791  Urfi wore a bold saree! Spread the flames of h...   \n",
       "\n",
       "         selftext                                                url  \\\n",
       "id                                                                     \n",
       "xylvpq             https://www.houstonchronicle.com/opinion/edito...   \n",
       "xylh3y             https://truthout.org/articles/sanders-bidens-m...   \n",
       "xyla6d  [removed]                                                      \n",
       "xykwzh  [removed]                                                      \n",
       "xykox1             https://countryconnect.in/entertainment-news/u...   \n",
       "\n",
       "        num_comments  upvote_ratio subreddit  \n",
       "id                                            \n",
       "xylvpq           688          0.97  politics  \n",
       "xylh3y           269          0.97  politics  \n",
       "xyla6d            24          0.26  politics  \n",
       "xykwzh             1          1.00  politics  \n",
       "xykox1             1          1.00  politics  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefd678-902c-4ec0-8371-a94226b86b1d",
   "metadata": {},
   "source": [
    "Seems like that worked!\n",
    "Let's double check if there are any duplicate - there shouldn't be, since I iterated over subsequent time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "905f61a1-e608-451a-a098-271e78632097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010, 7)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_df.groupby(level=0).first().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4116508-8a41-41ab-8ee6-17c25559a9d6",
   "metadata": {},
   "source": [
    "Now let's repeat the procedure for r/conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "20d0771d-29c5-429a-b349-e0a1f3d26330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10411, 7)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr2_df = create_submissions_df(subr2_data, subreddit2)\n",
    "subr2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "07bc12ef-b065-43a6-b621-9c7b707c652e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10411, 7)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr2_df.groupby(level=0).first().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "3eb3de44-de48-4f14-b20e-dcf35ee836a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xzewes</th>\n",
       "      <td>1665298432</td>\n",
       "      <td>Kanye is getting \"cancelled\" on twitter by the...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xzek87</th>\n",
       "      <td>1665297163</td>\n",
       "      <td>Attack On Free Speech' Paypals \"Misinformation...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://www.reddit.com/r/Conservative/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xzeit9</th>\n",
       "      <td>1665297021</td>\n",
       "      <td>Is it really any different if I move?</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://www.reddit.com/r/Conservative/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xzefy5</th>\n",
       "      <td>1665296708</td>\n",
       "      <td>Will some people always assume the worst about...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://www.reddit.com/r/Conservative/comments...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xzebti</th>\n",
       "      <td>1665296283</td>\n",
       "      <td>Any Help against Far-Left Liberals on Twitter?</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://www.reddit.com/r/Conservative/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        created_utc                                              title  \\\n",
       "id                                                                       \n",
       "xzewes   1665298432  Kanye is getting \"cancelled\" on twitter by the...   \n",
       "xzek87   1665297163  Attack On Free Speech' Paypals \"Misinformation...   \n",
       "xzeit9   1665297021              Is it really any different if I move?   \n",
       "xzefy5   1665296708  Will some people always assume the worst about...   \n",
       "xzebti   1665296283     Any Help against Far-Left Liberals on Twitter?   \n",
       "\n",
       "         selftext                                                url  \\\n",
       "id                                                                     \n",
       "xzewes  [removed]                                                      \n",
       "xzek87  [removed]  https://www.reddit.com/r/Conservative/comments...   \n",
       "xzeit9  [removed]  https://www.reddit.com/r/Conservative/comments...   \n",
       "xzefy5  [removed]  https://www.reddit.com/r/Conservative/comments...   \n",
       "xzebti  [removed]  https://www.reddit.com/r/Conservative/comments...   \n",
       "\n",
       "        num_comments  upvote_ratio     subreddit  \n",
       "id                                                \n",
       "xzewes             0           1.0  conservative  \n",
       "xzek87             0           1.0  conservative  \n",
       "xzeit9             0           1.0  conservative  \n",
       "xzefy5             1           1.0  conservative  \n",
       "xzebti             0           1.0  conservative  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32757d8c-a636-44a2-8dc7-6ebe34b530fe",
   "metadata": {},
   "source": [
    "Now let's merge this into one CSV and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "43cb7623-55f7-44ab-bddb-9a8d24a3f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_tot = pd.concat([subr1_df, subr2_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "710af7e6-787f-4025-91ac-d20c301da12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_tot.to_csv('../data/all_submissions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d4a26-03c4-4730-91f1-6cecc0eb2402",
   "metadata": {},
   "source": [
    "Looking at the 'selftext' columns - it seem that the vast majority of selftexts are empty, or removed/deleted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "23dde195-8c8f-4199-a9cd-341588cfeef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             0.775133\n",
       "[removed]    0.179962\n",
       "[deleted]    0.036482\n",
       "Name: selftext, dtype: float64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr_tot['selftext'].value_counts(normalize=True)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fea33-e021-437f-b586-deeca00f68d3",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf3324-4dda-4a6d-b2d5-8baeb5533b73",
   "metadata": {},
   "source": [
    "I would also like to look at comments to obtain more information on how people actually speak on these subreddits. Comments are not included in the submissions data, I will need to scrape them individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "787417ea-47bf-4dec-9373-44621fefe0d8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/comment/search\n",
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 2\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 3\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 4\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 7\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 8\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 9\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 10\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 11\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 12\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 13\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 15\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 16\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 17\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 524\n",
      "Connection unsuccessful\n",
      "------------------------------\n",
      "Day of the month 19\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 20\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 21\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 22\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 23\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 24\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 25\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 524\n",
      "Connection unsuccessful\n",
      "------------------------------\n",
      "Day of the month 27\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 28\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 29\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 30\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 31\n",
      "Status code: 200\n",
      "Total length of the list: 29\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 200\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 200\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Total length of the list: 31\n",
      "Great Success! Total number of posts/comments retrieved: 30956\n"
     ]
    }
   ],
   "source": [
    "subr1_comments = collect_subreddit_data(subreddit1, start_date='10-06-2022', n_days=31, rtype='comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "135b48d1-cf81-4e1f-bab1-fc15313752b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/comment/search\n",
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 524\n",
      "Connection unsuccessful\n",
      "------------------------------\n",
      "Day of the month 2\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 3\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 4\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 7\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 8\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 9\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 10\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 11\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 12\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 13\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 15\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 16\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 17\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 524\n",
      "Connection unsuccessful\n",
      "------------------------------\n",
      "Day of the month 19\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 20\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 21\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 22\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 23\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 24\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 25\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 27\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 28\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 29\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 30\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 31\n",
      "Status code: 200\n",
      "Total length of the list: 29\n",
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 200\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 200\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Total length of the list: 31\n",
      "Great Success! Total number of posts/comments retrieved: 30953\n"
     ]
    }
   ],
   "source": [
    "subr2_comments = collect_subreddit_data(subreddit2, start_date='10-06-2022', n_days=31, rtype='comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa380e4-99d1-465a-a684-74ce2809d73c",
   "metadata": {},
   "source": [
    "What do the keys of 'comment' dictionaries look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "65fa03bb-238b-4f1a-b2fe-fdc9d0230800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_awardings', 'archived', 'associated_award', 'author', 'author_created_utc', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'body', 'can_gild', 'collapsed', 'collapsed_because_crowd_control', 'collapsed_reason', 'collapsed_reason_code', 'comment_type', 'controversiality', 'created_utc', 'distinguished', 'edited', 'gilded', 'gildings', 'id', 'is_submitter', 'link_id', 'locked', 'no_follow', 'parent_id', 'permalink', 'retrieved_utc', 'score', 'score_hidden', 'send_replies', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_type', 'top_awarded_type', 'total_awards_received', 'treatment_tags', 'unrepliable_reason', 'updated_utc', 'body_sha1', 'utc_datetime_str'])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_comments[0]['data'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a26c0f-0e5d-4f58-9b7c-0290f7a91738",
   "metadata": {},
   "source": [
    "It seems like the actual comments are saved in 'body':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "80e544f6-4ddf-44b7-bb02-4fd00d02a71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If he was making calls to Georgia for someone else, imagine what he was doing for himself in SC.'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_comments[0]['data'][3]['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fb630-462f-4109-a943-5638dcf47dcf",
   "metadata": {},
   "source": [
    "We'll want to save these comments in another csv file. Let's write a function that saves\n",
    "1) id\n",
    "2) parent id \n",
    "3) the author\n",
    "4) date created\n",
    "5) actual comment ('body')\n",
    "6) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "79845575-3f3e-418f-8538-9a773ef88bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comments_df(subr_data, subr_name):\n",
    "    \n",
    "    #create a new list of dictionaries that has the format we want\n",
    "    df_l = []\n",
    "    features = ['id', 'parent_id', 'author', 'created_utc', 'body', 'score']\n",
    "    for subs_day in subr_data:\n",
    "        for post in subs_day['data']:\n",
    "            post_dict = {features[i]:post[x] for i,x in enumerate(features)}\n",
    "            df_l.append(post_dict)\n",
    "    com_df = pd.DataFrame(df_l)\n",
    "    com_df['subreddit'] = subr_name\n",
    "    com_df.set_index('id', inplace=True)\n",
    "    return com_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "28dfcc09-3d3e-48ec-875a-7255c373b4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30956, 6)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_com_df = create_comments_df(subr1_comments, subreddit1)\n",
    "subr1_com_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e7c79c56-d1f6-484b-aa26-df8834560909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>irhr7g7</th>\n",
       "      <td>4.084409e+10</td>\n",
       "      <td>stickznstonez_</td>\n",
       "      <td>1665212396</td>\n",
       "      <td>https://youtu.be/i1oCQ6bZ_Ws\\n\\nThis guy might...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr7fd</th>\n",
       "      <td>4.084099e+10</td>\n",
       "      <td>PoliticsModeratorBot</td>\n",
       "      <td>1665212395</td>\n",
       "      <td>Hi `PhilipLiptonSchrute`. [Your comment](/r/po...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr7bp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>valcatrina</td>\n",
       "      <td>1665212393</td>\n",
       "      <td>I am surprised it takes the FBI to draw this l...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr79r</th>\n",
       "      <td>4.084347e+10</td>\n",
       "      <td>StrillyBings</td>\n",
       "      <td>1665212392</td>\n",
       "      <td>If he was making calls to Georgia for someone ...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr79a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>After_Ad_9636</td>\n",
       "      <td>1665212391</td>\n",
       "      <td>Duh?\\n\\nWhy wouldn’t he?</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            parent_id                author  created_utc  \\\n",
       "id                                                         \n",
       "irhr7g7  4.084409e+10        stickznstonez_   1665212396   \n",
       "irhr7fd  4.084099e+10  PoliticsModeratorBot   1665212395   \n",
       "irhr7bp           NaN            valcatrina   1665212393   \n",
       "irhr79r  4.084347e+10          StrillyBings   1665212392   \n",
       "irhr79a           NaN         After_Ad_9636   1665212391   \n",
       "\n",
       "                                                      body  score subreddit  \n",
       "id                                                                           \n",
       "irhr7g7  https://youtu.be/i1oCQ6bZ_Ws\\n\\nThis guy might...      1  politics  \n",
       "irhr7fd  Hi `PhilipLiptonSchrute`. [Your comment](/r/po...      1  politics  \n",
       "irhr7bp  I am surprised it takes the FBI to draw this l...      1  politics  \n",
       "irhr79r  If he was making calls to Georgia for someone ...      1  politics  \n",
       "irhr79a                           Duh?\\n\\nWhy wouldn’t he?      1  politics  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_com_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b850e7-0c82-4534-990e-13b1d704415e",
   "metadata": {},
   "source": [
    "Not sure about those NaN values for parent Id, but let's keep this as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "4a893184-5991-4de0-ab96-9e67d7611e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30953, 6)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr2_com_df = create_comments_df(subr2_comments, subreddit2)\n",
    "subr2_com_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "db1a3a11-ab8b-4ef0-b7a5-8d5b8bb6a3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>irlvo5v</th>\n",
       "      <td>4.085140e+10</td>\n",
       "      <td>Domination11</td>\n",
       "      <td>1665298765</td>\n",
       "      <td>this is just such a shittily written article a...</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irlvmx0</th>\n",
       "      <td>4.084825e+10</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1665298736</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irlvm7f</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SadNYSportsFan-11209</td>\n",
       "      <td>1665298721</td>\n",
       "      <td>But but ring wing white supremacist terrorists...</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irlvj5a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1665298654</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irlvfqo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EpicToshima</td>\n",
       "      <td>1665298577</td>\n",
       "      <td>Why should she visit the border when the borde...</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            parent_id                author  created_utc  \\\n",
       "id                                                         \n",
       "irlvo5v  4.085140e+10          Domination11   1665298765   \n",
       "irlvmx0  4.084825e+10             [deleted]   1665298736   \n",
       "irlvm7f           NaN  SadNYSportsFan-11209   1665298721   \n",
       "irlvj5a           NaN             [deleted]   1665298654   \n",
       "irlvfqo           NaN           EpicToshima   1665298577   \n",
       "\n",
       "                                                      body  score  \\\n",
       "id                                                                  \n",
       "irlvo5v  this is just such a shittily written article a...      1   \n",
       "irlvmx0                                          [removed]      1   \n",
       "irlvm7f  But but ring wing white supremacist terrorists...      1   \n",
       "irlvj5a                                          [removed]      1   \n",
       "irlvfqo  Why should she visit the border when the borde...      1   \n",
       "\n",
       "            subreddit  \n",
       "id                     \n",
       "irlvo5v  conservative  \n",
       "irlvmx0  conservative  \n",
       "irlvm7f  conservative  \n",
       "irlvj5a  conservative  \n",
       "irlvfqo  conservative  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr2_com_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f6fa4-2be1-46be-816e-3f96d366aef8",
   "metadata": {},
   "source": [
    "Now we can merge the two, and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "3f9df34f-0392-4443-9ed1-ded3e3828508",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_com_tot = pd.concat([subr1_com_df, subr2_com_df])\n",
    "subr_com_tot.to_csv('../data/all_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b11b8-a457-401e-92a0-d6bd13f569d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
