{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15bf9c6-3ae8-41dc-80d0-f9cc4aabfede",
   "metadata": {},
   "source": [
    "# Data Collection \n",
    "\n",
    "This notebook 1 (out of 5) for the NLP Reddit Project\n",
    "Notebook by: <b>Martijn de Vries</b><br>\n",
    "martijndevries91@gmail.com <br>\n",
    "https://github.com/martijndevries/NLP_Reddit <br>\n",
    "\n",
    "<b> Note: </b> Given the 2023 Reddit API changes, PushShift API No longer works and this notebook can no longer be run to completion. The data is is still available, in the data folder of this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aad84c-d2c4-4f6f-a091-4cffe7126ffc",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "A US political consultancy company is researching how news sources and discussed topics differ between the US political mainstream and the conservative right-wing media. In the last decade or so, the US political right-wing has been increasingly described as living in an entirely separate information ecosystem from the political mainstream. In order to gauge how intense this effect is, we will collect, process, and classify the Reddit content of two politically-themed subreddit that reflect the mainstream and conservative voters respectively: <b>r/politics</b> and <b>r/conservative</b>. \n",
    "\n",
    "For this project, we will build two separate branches of models: one for post submissions (largely consisting of links to news sites), and another for comments (consisting of actual Reddit users discussing political news). As this is a binary classification problem where the two classes are of equal interest and will be approximately balanced, we will use the accuracy score as the main metric to gauge the success of the classification model. \n",
    "\n",
    "Because political news is always evolving, we have chosen a specific moment in time: the month leading up to the 2022 midterms, October 6th to November 6th 2022. This ensures that 1) the same news cycle is covered for both subreddits, 2) both subreddits were at peak activity, and 3) maximum potential for interesting insights in the way that news is discussed within these two subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad31c95-8e0a-4d6e-9ebd-03b199a60419",
   "metadata": {},
   "source": [
    "## In this Notebook\n",
    "\n",
    "I will use the Pushshift API to obtain data from the two subreddits (r/politics and r/conservative) for the specified data. I will then extract the information I want from the obtained data, convert to a pandas dataframe and save the dataframes to two csv files: all_submissions.csv and all_comments.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7585b2c-24c1-49fb-af7f-c9e77e7ba8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime as dt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf6fc1-9b7a-4c32-85df-75a91f4bcb40",
   "metadata": {},
   "source": [
    "## Posts\n",
    "\n",
    "The first thing I would like to is to collect all posts made in the specified month (October 6th, 2022 until November 6th, 2022). First let's define the two subreddits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be7da40-b915-460d-8d3a-f8677e0e6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit1 = 'politics'\n",
    "subreddit2 = 'conservative'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a03375-7540-4c6d-948f-692e5465822c",
   "metadata": {},
   "source": [
    "Now I'll write a function to actually collect data with Pushshift API. From previous experiments, it seems that I'm not always able to succesfully connect to the API. So I'll build in a couple of failsafes - I'll loop over each day of the month, and collect all the data. At the end of the loop, repeat for the days where it didn't manage to connect succesfully, until all data has been collected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f2f172-b419-4554-af56-62e545d6259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_subreddit_data(subreddit, start_date='10-06-2022', n_days=30, rtype='submission'):\n",
    "    \"\"\"\n",
    "    Collect submissions/comments from a given subreddit using requests and Pushshift API\n",
    "    \n",
    "    Parameters:\n",
    "        subreddit (str): the subreddit to collect data from\n",
    "        start_date (str): the starting date in mm-dd-yyyy\n",
    "        n_days (int): the number of days to loop over after the start date. one requests will be made per day up to 1000 items\n",
    "        rtype (str): whether to collect submissins or comments\n",
    "    Returns:\n",
    "        a list of json objects for each day\n",
    "    \"\"\"\n",
    "    \n",
    "    pushshift_url= 'https://api.pushshift.io/reddit/' + rtype + '/search'\n",
    "    subr_data = [] #to be returned\n",
    "    success_list = [] #to keep track of which days have been collected\n",
    "    mm, dd, yy = start_date.split('-')\n",
    "    tot_posts = 0\n",
    "    \n",
    "    q = 0 \n",
    "    while len(success_list) < n_days: \n",
    "        \n",
    "        s_epoch_start = int(dt.datetime(int(yy),int(mm),int(dd),0,0).timestamp())\n",
    "        for i in range(1, n_days+1):\n",
    "            \n",
    "            print('-' * 30)\n",
    "            if i in success_list: continue\n",
    "            \n",
    "            print(f'Day of the month {i}')\n",
    "            s_epoch_start += 24*3600\n",
    "            s_epoch_end = s_epoch_start + 24*3600\n",
    "            params = {'subreddit':subreddit, 'since':s_epoch_start, 'until':s_epoch_end , 'size':1000}\n",
    "            \n",
    "            res = requests.get(pushshift_url, params)\n",
    "            print(f'Status code: {res.status_code}')\n",
    "            \n",
    "            if res.status_code != 200:\n",
    "                print('Connection unsuccessful')\n",
    "                continue\n",
    "            else:\n",
    "                data = res.json()\n",
    "                if len(data['data']) == 0:\n",
    "                    print('Connection succesful but no data retrieved.') \n",
    "                    continue\n",
    "                subr_data.append(data)\n",
    "                success_list.append(i) #don't need try this day again on subsequent loops\n",
    "                tot_posts += len(data['data'])\n",
    "                \n",
    "            time.sleep(15) #polite\n",
    "        print(f'Total length of the list: {len(success_list)}')\n",
    "        q +=1\n",
    "        if q == 10: break # Failsafe to make sure that if the API is down, the while loop doesn't keep going forever\n",
    "    print(f'Great Success! Total number of posts/comments retrieved: {tot_posts}')\n",
    "    return subr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718ca04a-9048-4e25-a4ce-b6772023ea89",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 2\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 3\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 4\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 7\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 8\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 9\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 10\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 11\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 12\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 13\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 15\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 16\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 17\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 19\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 20\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 21\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 22\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 23\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 24\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 25\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 27\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 28\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 29\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 30\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 31\n",
      "Status code: 200\n",
      "Total length of the list: 31\n",
      "Great Success! Total number of posts/comments retrieved: 10010\n"
     ]
    }
   ],
   "source": [
    "subr1_data = collect_subreddit_data(subreddit1, start_date='10-06-2022', n_days=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ddcdfe7-63c0-46c9-a823-3a77fc6db438",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 2\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 3\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 4\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 7\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 8\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 9\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 10\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 11\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 12\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 13\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 15\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 16\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 17\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 19\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 20\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 21\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 22\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 23\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 24\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 25\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 27\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 28\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 29\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 30\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 31\n",
      "Status code: 200\n",
      "Total length of the list: 31\n",
      "Great Success! Total number of posts/comments retrieved: 10411\n"
     ]
    }
   ],
   "source": [
    "subr2_data = collect_subreddit_data(subreddit2, start_date='10-06-2022', n_days=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8872a5-2c71-4975-9ba7-52fa1ef1b775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_awardings', 'allow_live_comments', 'archived', 'author', 'author_created_utc', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders', 'can_gild', 'category', 'content_categories', 'contest_mode', 'created_utc', 'discussion_type', 'distinguished', 'domain', 'edited', 'gilded', 'gildings', 'hidden', 'hide_score', 'id', 'is_created_from_ads_ui', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked', 'media', 'media_embed', 'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'post_hint', 'preview', 'pwls', 'quarantine', 'removed_by', 'removed_by_category', 'retrieved_on', 'score', 'secure_media', 'secure_media_embed', 'selftext', 'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_name_prefixed', 'subreddit_subscribers', 'subreddit_type', 'suggested_sort', 'thumbnail', 'thumbnail_height', 'thumbnail_width', 'title', 'top_awarded_type', 'total_awards_received', 'treatment_tags', 'upvote_ratio', 'url', 'url_overridden_by_dest', 'view_count', 'whitelist_status', 'wls', 'retrieved_utc', 'updated_utc', 'utc_datetime_str'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the keys of a single post dictionary\n",
    "subr1_data[0]['data'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3dbbc8-0847-4f88-a800-015ad9058a67",
   "metadata": {},
   "source": [
    "subr1_data and subr2_data are now lists with the following structure:\n",
    "1) each entry is all the posts for a given day\n",
    "2) indexing into the lists, selecting ['data'], gives me a list with all the data for that day\n",
    "3) indexing into this gives me a dictionary with the data for a single post\n",
    "\n",
    "Let's write a function to take these lists, and return a pandas dataframe with\n",
    "1) the unique ID of the post\n",
    "2) the time it was posted\n",
    "3) the title\n",
    "4) the selftext (if present)\n",
    "5) the URL the post links to\n",
    "5) the number of comments\n",
    "6) the upvote ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70967b21-e38c-484a-99ad-b3d138b4e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submissions_df(subr_data, subr_name):\n",
    "    \"\"\"\n",
    "    Take the posts output of collect_subreddit_data and turn it into a pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_l = []\n",
    "    features = ['id', 'created_utc', 'title', 'selftext', 'url', 'num_comments', 'upvote_ratio']\n",
    "    for subs_day in subr_data:\n",
    "        \n",
    "        for post in subs_day['data']:\n",
    "            post_dict = {features[i]:post[x] for i,x in enumerate(features)}\n",
    "            df_l.append(post_dict)\n",
    "            \n",
    "    sub_df = pd.DataFrame(df_l)\n",
    "    sub_df['subreddit'] = subr_name\n",
    "    sub_df.set_index('id', inplace=True)\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7dc7c-d482-4754-8339-4e991739164f",
   "metadata": {},
   "source": [
    "Let's try this out for our first subreddit, r/politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28e65dc9-daaa-4caf-8173-d266a5979906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_df = create_submissions_df(subr1_data, subreddit1)\n",
    "print(subr1_df.shape)\n",
    "subr1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefd678-902c-4ec0-8371-a94226b86b1d",
   "metadata": {},
   "source": [
    "Seems like that worked!\n",
    "Let's double check if there are any duplicates - there shouldn't be, since I iterated over subsequent time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905f61a1-e608-451a-a098-271e78632097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_df.groupby(level=0).first().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4116508-8a41-41ab-8ee6-17c25559a9d6",
   "metadata": {},
   "source": [
    "Now let's repeat the procedure for r/conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20d0771d-29c5-429a-b349-e0a1f3d26330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10411, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xylz2r</th>\n",
       "      <td>1665212391</td>\n",
       "      <td>Why do many conservatives consider the student...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xylxh4</th>\n",
       "      <td>1665212224</td>\n",
       "      <td>Cocaine: How Albanian gangs took control of Br...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.telegraph.co.uk/world-news/2022/09...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xylwcf</th>\n",
       "      <td>1665212109</td>\n",
       "      <td>Ukraine: Walter Mead - The Question on Putin’s...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.wsj.com/amp/articles/would-we-risk...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.55</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xyltrr</th>\n",
       "      <td>1665211841</td>\n",
       "      <td>CONSERVATIVE ANSWERS ONLY</td>\n",
       "      <td>[removed]</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xylqmu</th>\n",
       "      <td>1665211523</td>\n",
       "      <td>Iran: David Patrikarakos = This revolt is exis...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.telegraph.co.uk/news/2022/10/07/re...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        created_utc                                              title  \\\n",
       "id                                                                       \n",
       "xylz2r   1665212391  Why do many conservatives consider the student...   \n",
       "xylxh4   1665212224  Cocaine: How Albanian gangs took control of Br...   \n",
       "xylwcf   1665212109  Ukraine: Walter Mead - The Question on Putin’s...   \n",
       "xyltrr   1665211841                          CONSERVATIVE ANSWERS ONLY   \n",
       "xylqmu   1665211523  Iran: David Patrikarakos = This revolt is exis...   \n",
       "\n",
       "         selftext                                                url  \\\n",
       "id                                                                     \n",
       "xylz2r  [removed]                                                      \n",
       "xylxh4             https://www.telegraph.co.uk/world-news/2022/09...   \n",
       "xylwcf             https://www.wsj.com/amp/articles/would-we-risk...   \n",
       "xyltrr  [removed]                                                      \n",
       "xylqmu             https://www.telegraph.co.uk/news/2022/10/07/re...   \n",
       "\n",
       "        num_comments  upvote_ratio     subreddit  \n",
       "id                                                \n",
       "xylz2r             0          1.00  conservative  \n",
       "xylxh4             2          0.64  conservative  \n",
       "xylwcf             8          0.55  conservative  \n",
       "xyltrr             0          1.00  conservative  \n",
       "xylqmu             2          0.70  conservative  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr2_df = create_submissions_df(subr2_data, subreddit2)\n",
    "print(subr2_df.shape)\n",
    "subr2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32757d8c-a636-44a2-8dc7-6ebe34b530fe",
   "metadata": {},
   "source": [
    "Now let's merge this into one CSV and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43cb7623-55f7-44ab-bddb-9a8d24a3f90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20421, 7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr_tot = pd.concat([subr1_df, subr2_df])\n",
    "#subr_tot.to_csv('../data/all_submissions.csv') #commented out to not overwrite my data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d4a26-03c4-4730-91f1-6cecc0eb2402",
   "metadata": {},
   "source": [
    "Looking at the 'selftext' columns - it seem that the vast majority of selftexts are empty, or removed/deleted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23dde195-8c8f-4199-a9cd-341588cfeef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             0.775133\n",
       "[removed]    0.179962\n",
       "[deleted]    0.036482\n",
       "Name: selftext, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr_tot['selftext'].value_counts(normalize=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7990795d-ef6c-4fd4-bc9e-a172ed3412ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915772978796338"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr_tot['selftext'].value_counts(normalize=True)[:3].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495615ba-98e0-48c4-87dd-b0b82400cfa5",
   "metadata": {},
   "source": [
    "So I probably should just ignore the selftext and focus on the titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fea33-e021-437f-b586-deeca00f68d3",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf3324-4dda-4a6d-b2d5-8baeb5533b73",
   "metadata": {},
   "source": [
    "Secondly, I would like to look at comments to obtain more information on how people actually speak on these subreddits. Comments are not included in the submissions data, I will need to scrape them individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "787417ea-47bf-4dec-9373-44621fefe0d8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 2\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 3\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 4\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 7\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 8\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 9\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 10\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 11\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 12\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 13\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 15\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 16\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 17\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 19\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 20\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 21\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 22\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 23\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 24\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 25\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 27\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 28\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 29\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 30\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 31\n",
      "Status code: 200\n",
      "Total length of the list: 31\n",
      "Great Success! Total number of posts/comments retrieved: 30956\n"
     ]
    }
   ],
   "source": [
    "subr1_comments = collect_subreddit_data(subreddit1, start_date='10-06-2022', n_days=31, rtype='comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "135b48d1-cf81-4e1f-bab1-fc15313752b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Day of the month 1\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 2\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 3\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 4\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 5\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 524\n",
      "Connection unsuccessful\n",
      "------------------------------\n",
      "Day of the month 7\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 8\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 9\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 10\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 11\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 12\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 13\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 14\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 15\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 16\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 17\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 18\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 19\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 20\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 21\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 22\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 23\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 24\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 25\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 26\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 27\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 28\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 29\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 30\n",
      "Status code: 200\n",
      "------------------------------\n",
      "Day of the month 31\n",
      "Status code: 200\n",
      "Total length of the list: 30\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Day of the month 6\n",
      "Status code: 200\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "Total length of the list: 31\n",
      "Great Success! Total number of posts/comments retrieved: 30955\n"
     ]
    }
   ],
   "source": [
    "subr2_comments = collect_subreddit_data(subreddit2, start_date='10-06-2022', n_days=31, rtype='comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa380e4-99d1-465a-a684-74ce2809d73c",
   "metadata": {},
   "source": [
    "What do the keys of 'comment' dictionaries look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65fa03bb-238b-4f1a-b2fe-fdc9d0230800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_awardings', 'archived', 'associated_award', 'author', 'author_created_utc', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'body', 'can_gild', 'collapsed', 'collapsed_because_crowd_control', 'collapsed_reason', 'collapsed_reason_code', 'comment_type', 'controversiality', 'created_utc', 'distinguished', 'edited', 'gilded', 'gildings', 'id', 'is_submitter', 'link_id', 'locked', 'no_follow', 'parent_id', 'permalink', 'retrieved_utc', 'score', 'score_hidden', 'send_replies', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_type', 'top_awarded_type', 'total_awards_received', 'treatment_tags', 'unrepliable_reason', 'updated_utc', 'body_sha1', 'utc_datetime_str'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_comments[0]['data'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a26c0f-0e5d-4f58-9b7c-0290f7a91738",
   "metadata": {},
   "source": [
    "It seems like the actual comments are saved in 'body':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80e544f6-4ddf-44b7-bb02-4fd00d02a71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If he was making calls to Georgia for someone else, imagine what he was doing for himself in SC.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_comments[0]['data'][3]['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fb630-462f-4109-a943-5638dcf47dcf",
   "metadata": {},
   "source": [
    "We'll want to save these comments in another csv file. Let's write a function that saves\n",
    "1) id\n",
    "2) parent id \n",
    "3) the author\n",
    "4) date created\n",
    "5) actual comment ('body')\n",
    "6) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79845575-3f3e-418f-8538-9a773ef88bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comments_df(subr_data, subr_name):\n",
    "    \"\"\"\n",
    "    Take the comments output of collect_subreddit_data and turn it into a pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_l = []\n",
    "    features = ['id', 'parent_id', 'author', 'created_utc', 'body', 'score']\n",
    "    for subs_day in subr_data:\n",
    "        for post in subs_day['data']:\n",
    "            post_dict = {features[i]:post[x] for i,x in enumerate(features)}\n",
    "            df_l.append(post_dict)\n",
    "    com_df = pd.DataFrame(df_l)\n",
    "    com_df['subreddit'] = subr_name\n",
    "    com_df.set_index('id', inplace=True)\n",
    "    return com_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28dfcc09-3d3e-48ec-875a-7255c373b4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30956, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_com_df = create_comments_df(subr1_comments, subreddit1)\n",
    "subr1_com_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7c79c56-d1f6-484b-aa26-df8834560909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>irhr7g7</th>\n",
       "      <td>4.084409e+10</td>\n",
       "      <td>stickznstonez_</td>\n",
       "      <td>1665212396</td>\n",
       "      <td>https://youtu.be/i1oCQ6bZ_Ws\\n\\nThis guy might...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr7fd</th>\n",
       "      <td>4.084099e+10</td>\n",
       "      <td>PoliticsModeratorBot</td>\n",
       "      <td>1665212395</td>\n",
       "      <td>Hi `PhilipLiptonSchrute`. [Your comment](/r/po...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr7bp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>valcatrina</td>\n",
       "      <td>1665212393</td>\n",
       "      <td>I am surprised it takes the FBI to draw this l...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr79r</th>\n",
       "      <td>4.084347e+10</td>\n",
       "      <td>StrillyBings</td>\n",
       "      <td>1665212392</td>\n",
       "      <td>If he was making calls to Georgia for someone ...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr79a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>After_Ad_9636</td>\n",
       "      <td>1665212391</td>\n",
       "      <td>Duh?\\n\\nWhy wouldn’t he?</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            parent_id                author  created_utc  \\\n",
       "id                                                         \n",
       "irhr7g7  4.084409e+10        stickznstonez_   1665212396   \n",
       "irhr7fd  4.084099e+10  PoliticsModeratorBot   1665212395   \n",
       "irhr7bp           NaN            valcatrina   1665212393   \n",
       "irhr79r  4.084347e+10          StrillyBings   1665212392   \n",
       "irhr79a           NaN         After_Ad_9636   1665212391   \n",
       "\n",
       "                                                      body  score subreddit  \n",
       "id                                                                           \n",
       "irhr7g7  https://youtu.be/i1oCQ6bZ_Ws\\n\\nThis guy might...      1  politics  \n",
       "irhr7fd  Hi `PhilipLiptonSchrute`. [Your comment](/r/po...      1  politics  \n",
       "irhr7bp  I am surprised it takes the FBI to draw this l...      1  politics  \n",
       "irhr79r  If he was making calls to Georgia for someone ...      1  politics  \n",
       "irhr79a                           Duh?\\n\\nWhy wouldn’t he?      1  politics  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr1_com_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b850e7-0c82-4534-990e-13b1d704415e",
   "metadata": {},
   "source": [
    "Not sure about those NaN values for parent Id, but let's keep this as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a893184-5991-4de0-ab96-9e67d7611e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30955, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr2_com_df = create_comments_df(subr2_comments, subreddit2)\n",
    "subr2_com_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db1a3a11-ab8b-4ef0-b7a5-8d5b8bb6a3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>irhr6tz</th>\n",
       "      <td>4.084212e+10</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1665212380</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr2rs</th>\n",
       "      <td>4.084264e+10</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1665212278</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr1rl</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Specialist861</td>\n",
       "      <td>1665212253</td>\n",
       "      <td>This reeks of the \"Y'all will get BidenBucks i...</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr1pu</th>\n",
       "      <td>4.084394e+10</td>\n",
       "      <td>WholesomeMorning</td>\n",
       "      <td>1665212252</td>\n",
       "      <td>This sub proves otherwise lol</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irhr140</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ChunkyArsenio</td>\n",
       "      <td>1665212236</td>\n",
       "      <td>&amp;gt;  **No Paywall:**\\n \\nhttps://archive.ph/S...</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            parent_id            author  created_utc  \\\n",
       "id                                                     \n",
       "irhr6tz  4.084212e+10         [deleted]   1665212380   \n",
       "irhr2rs  4.084264e+10         [deleted]   1665212278   \n",
       "irhr1rl           NaN     Specialist861   1665212253   \n",
       "irhr1pu  4.084394e+10  WholesomeMorning   1665212252   \n",
       "irhr140           NaN     ChunkyArsenio   1665212236   \n",
       "\n",
       "                                                      body  score  \\\n",
       "id                                                                  \n",
       "irhr6tz                                          [removed]      1   \n",
       "irhr2rs                                          [removed]      1   \n",
       "irhr1rl  This reeks of the \"Y'all will get BidenBucks i...      1   \n",
       "irhr1pu                      This sub proves otherwise lol      1   \n",
       "irhr140  &gt;  **No Paywall:**\\n \\nhttps://archive.ph/S...      1   \n",
       "\n",
       "            subreddit  \n",
       "id                     \n",
       "irhr6tz  conservative  \n",
       "irhr2rs  conservative  \n",
       "irhr1rl  conservative  \n",
       "irhr1pu  conservative  \n",
       "irhr140  conservative  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr2_com_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f6fa4-2be1-46be-816e-3f96d366aef8",
   "metadata": {},
   "source": [
    "Now we can merge the two, and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f9df34f-0392-4443-9ed1-ded3e3828508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61911, 6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subr_com_tot = pd.concat([subr1_com_df, subr2_com_df])\n",
    "subr_com_tot.shape\n",
    "#subr_com_tot.to_csv('../data/all_comments.csv') #commented out to not overwrite my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97be464-07d5-48ef-902e-918baf3a1dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
